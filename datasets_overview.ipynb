{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc559d4",
   "metadata": {},
   "source": [
    "# Dataset Overview (for Amazon Reviews, Essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aaf6007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "reviews_parent_dir = 'datasets/reviews/'\n",
    "essays_parent_dir = 'datasets/asap-aes/'\n",
    "\n",
    "def load_reviews(files=None, nrows_per_type=None):\n",
    "    if not files:\n",
    "        files = [f for f in os.listdir('datasets/reviews/') if f.split('.')[1]=='json']\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        df = pd.read_json(reviews_parent_dir + f, lines=True, nrows=nrows_per_type)\n",
    "        df['type'] = f.split('-')[0]\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs).reset_index()\n",
    "\n",
    "def load_essays(train=True, valid=True, test=True):\n",
    "    files = []\n",
    "    if train: files.append('train_set.json')\n",
    "    if valid: files.append('valid_set.json')\n",
    "    if test:  files.append('test_set.json')\n",
    "    return (pd.read_json(essays_parent_dir + f, lines=False) for f in files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db432f0e",
   "metadata": {},
   "source": [
    "# Amazon Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "27b9c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_data = load_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fcf419e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>08 22, 2013</td>\n",
       "      <td>A34A1UP40713F8</td>\n",
       "      <td>B00009W3I4</td>\n",
       "      <td>{'Style:': ' Dryer Vent'}</td>\n",
       "      <td>James. Backus</td>\n",
       "      <td>I like this as a vent as well as something tha...</td>\n",
       "      <td>Great product</td>\n",
       "      <td>1377129600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>appliances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>02 8, 2016</td>\n",
       "      <td>A1AHW6I678O6F2</td>\n",
       "      <td>B00009W3PA</td>\n",
       "      <td>{'Size:': ' 6-Foot'}</td>\n",
       "      <td>kevin.</td>\n",
       "      <td>good item</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1454889600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>appliances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>08 5, 2015</td>\n",
       "      <td>A8R48NKTGCJDQ</td>\n",
       "      <td>B00009W3PA</td>\n",
       "      <td>{'Size:': ' 6-Foot'}</td>\n",
       "      <td>CDBrannom</td>\n",
       "      <td>Fit my new LG dryer perfectly.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1438732800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>appliances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>04 24, 2015</td>\n",
       "      <td>AR3OHHHW01A8E</td>\n",
       "      <td>B00009W3PA</td>\n",
       "      <td>{'Size:': ' 6-Foot'}</td>\n",
       "      <td>Calvin E Reames</td>\n",
       "      <td>Good value for electric dryers</td>\n",
       "      <td>Perfect size</td>\n",
       "      <td>1429833600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>appliances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>03 21, 2015</td>\n",
       "      <td>A2CIEGHZ7L1WWR</td>\n",
       "      <td>B00009W3PA</td>\n",
       "      <td>{'Size:': ' 6-Foot'}</td>\n",
       "      <td>albert j. kong</td>\n",
       "      <td>Price and delivery was excellent.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1426896000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>appliances</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0      0        5      True  08 22, 2013  A34A1UP40713F8  B00009W3I4   \n",
       "1      1        5      True   02 8, 2016  A1AHW6I678O6F2  B00009W3PA   \n",
       "2      2        5      True   08 5, 2015   A8R48NKTGCJDQ  B00009W3PA   \n",
       "3      3        5      True  04 24, 2015   AR3OHHHW01A8E  B00009W3PA   \n",
       "4      4        5      True  03 21, 2015  A2CIEGHZ7L1WWR  B00009W3PA   \n",
       "\n",
       "                       style     reviewerName  \\\n",
       "0  {'Style:': ' Dryer Vent'}    James. Backus   \n",
       "1       {'Size:': ' 6-Foot'}           kevin.   \n",
       "2       {'Size:': ' 6-Foot'}        CDBrannom   \n",
       "3       {'Size:': ' 6-Foot'}  Calvin E Reames   \n",
       "4       {'Size:': ' 6-Foot'}   albert j. kong   \n",
       "\n",
       "                                          reviewText        summary  \\\n",
       "0  I like this as a vent as well as something tha...  Great product   \n",
       "1                                          good item     Five Stars   \n",
       "2                     Fit my new LG dryer perfectly.     Five Stars   \n",
       "3                     Good value for electric dryers   Perfect size   \n",
       "4                  Price and delivery was excellent.     Five Stars   \n",
       "\n",
       "   unixReviewTime vote image        type  \n",
       "0      1377129600  NaN   NaN  appliances  \n",
       "1      1454889600  NaN   NaN  appliances  \n",
       "2      1438732800  NaN   NaN  appliances  \n",
       "3      1429833600  NaN   NaN  appliances  \n",
       "4      1426896000  NaN   NaN  appliances  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3bc27a",
   "metadata": {},
   "source": [
    "### Sample Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b4d067af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------- (appliances) --------------------------------\n",
      "\n",
      "(Score: 5)  We have 24 foot of solid dryer vent pipe ending in 3 right-angles before going through the floor into the flexible dryer-vent hose coming from the dryer.  I can't get behind the dryer without moving both the washer and dryer and they are HEAVY.  So being lazy I decided to clean the vent from the outside of the house inward.  I didn't use a vacuum cleaner or a blower or suction of any kind.  I did tighten each section of tubing with pliers and taped them.  I threaded all 24 foot of tubing with the brush on the end into the outside vent and then backed it out.  I got a good amount of lint clods out.  Then I turned on the dryer to blow everything out.  I got no air coming out at all.  My fear had come true, I had forced gobs of lint into the right-angles at the end of the run.  I still didn't want to move that washer and dryer so I figured I'd try one other thing, use the clodbuster attachment.  Now I'm really getting lazy so I tightened each tubing section by hand (no pliers) and didn't use tape.  I pushed all 24 foot of tubing into the vent until I hit some resistance and then turned the tubing by hand (too lazy to hook the drill up).  Then I pulled it all out and there wasn't any lint at all that came out. So now I'm resigned to having to move the washer and dryer, but before I do I figured I might as well turn the dryer on and see what happens.  Lots of lint clods blew out and kept coming out for about 20 seconds.  I've attached pictures of it.  I'm really happy with this product and if it worked for me with all the shortcuts I took it will probably work great for you.  As a point of reference we built this house five years ago and this is the first time I ever cleaned the vent.  A load of ten bath towels used to take 45 minutes to dry, lately it's been taking 3 to 4 hours, so I knew I couldn't put cleaning the pipe off any longer.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "(Score: 3)  first thing first: it works. the kit is great in what it consists of and the price is just right i think. to call someone to clean my dryer vents i got quoted from 80 all the way up to 200 bucks. so if you were able to do it yourself you will need to invest a bit more in a \"construction\" vacuum that cost about 80-100 bucks and start the savings basically from the second time you do it.\n",
      "\n",
      "so whats with the 3*? my brush broke inside my vent!!!! while i was pulling it out, and yes i was using a drill, all the pieces came out except the round brush. i had to climb to my attic and push it from the other side to come out... what was supposed to be an easy task ended up with me spending over an hour extra in climbing in my attic, disassembling the HVAC pipe so that i can get in there and push down on the brush...\n",
      "\n",
      "another minus for this kit is that while it is fairly bendy, it will not go very smoothly through your flexible insulated pipes and most likely push the pipe out from its connector.\n",
      "\n",
      "with all that said, if your vent duct doesnt have to many bends, and you want to take the risk (maybe i had a defective kit that the brush broke), you might save a lot of money doing it yourself!\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (arts_crafts_and_sewing) --------------------------------\n",
      "\n",
      "(Score: 5)  Sharp and stout, works very well.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "(Score: 5)  I got this paper for large Christmas presents, and it works PERFECT for it. Depending on what is underneath, you may need to wrap it twice around; but nonetheless I've been using my first roll for TWO YEARS and I am just coming up to order a second one because the first is getting low.\n",
      "\n",
      "It rolls out nicely, the variety of colors is top notch, and the price is SO nice, especially when you compare it to wrapping paper! I love pairing this light blue with red and white candy cane ribbons and bows... it's so festive!  It's super easy to cut, just like quality wrapping paper.  Definitely recommend this over regular wrapping paper, especially when it comes to large presents!\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (automotive) --------------------------------\n",
      "\n",
      "(Score: 4)  Use to polish my aluminum airplane. Works good with the \"Nuvite\" products and with the Porter Cable random orbit sander, gets into tight places\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "(Score: 2)  Just as I thought...it tells you how to rebuild the transmission, differential and engine (who is going to do that??) it does not tell you how to do some of the things you are actually going to attempt in your garage.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (books) --------------------------------\n",
      "\n",
      "(Score: 4)  Enjoyed more than the previous one\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "(Score: 5)  This works perfectly with my 65\" Vizio.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (cellphones_and_accessories) --------------------------------\n",
      "\n",
      "(Score: 2)  I owned this for a few weeks and found that it was a bit uncomfortable when wearing for more than a few minutes.\n",
      "\n",
      "Also, when using in the car, the person on the other end had a very hard time hearing me due to all the background noise (even with the windows closed and radio off, of course).\n",
      "\n",
      "I do, however, like the little battery charger and clip that comes with it -- it made it easier to carry around (ie. you could clip it to your briefcase, belt, or phone holder).\n",
      "\n",
      "I sold it at auction and bought the 510, and it seems a bit more comfortable, and also produces less background noise in the car.  however its a bit bulkier.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "(Score: 4)  I have had several headsets, and this one has lastest longer than any of them.  It holds a charge for a long time, whereas the other ones would die sooner.\n",
      "\n",
      "Good sound quality, comfortable fit.  Although the microphone extends as a boom, I never use it extended.  The quality and comfort are just fine without it extended.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (clothing_shoes_and_jewelry) --------------------------------\n",
      "\n",
      "(Score: 1)  This costume is very cheaply made.  The back is solid light pink and is very see-through.  The wig leaves much to be desired. Don't waste your money.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "(Score: 5)  I purchased this for my 4 year old's witch costume. It's a great height for a child and the straw bristles are great. Yes, they are a tad sparse but this item is under $9 so what does everyone expect?? (other bad reviews) It's a costume prop. Very much worth the money. I would recommend. I did not have any problems with bristles falling off. They seem sturdy enough for a costume. I'm happy I took a chance on this because it will make the perfect addition to my daughter's costume:\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (fashion) --------------------------------\n",
      "\n",
      "(Score: 5)  Size really depends on the brand.  I wear a 6.5 in Nike and they fit me perfectly.  These shoes are comfortable, they wrap around my feet like a bandage but do not restrict movement.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "(Score: 3)  No arch support but l love the colors!\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (home_and_kitchen) --------------------------------\n",
      "\n",
      "(Score: 3)  Didn't care for the facial painting\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "(Score: 5)  I have had this one for several years and still going strong.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (movies_and_tv) --------------------------------\n",
      "\n",
      "(Score: 5)  This movie was my favorite as a kid and now, as an adult. I was watching again today and realized that the Burgermeister is really my sister. LOL Who knew?\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "(Score: 5)  I started reading this book last week and decided to rent the movie. They only had this version of Jane Eyre and was hesitant to watch it because I had never heard of the actors before. As the movie started I noticed that  it skipped the beginning of the book (began at the red-room incident)and  spent more time towards Jane Eyre as an adult. When I first saw Ciaran  Hinds (Mr. Rochester) I thought - this man isn't very attractive and he is  really mean!  Jane Eyre will never fall for him! But, Mr. Hinds played the  role wonderfully and even I looked beyond his roughness and fell inlove  with the character!  Samantha Morton played a wonderful Jane Eyre and I  really felt the chemistry between the two throughout the movie.  I think my  favorite scene was when he was waiting for Jane to get back from preparing  for her aunts funeral and was very jealous.  And the ending made me cry!  I  later rented a different version of Jane Eyre with William Hurt in it, and  disliked it very much.  There was no chemistry between the lead actors and  I was glad that I rented this version first!\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (office_products) --------------------------------\n",
      "\n",
      "(Score: 5)  great price and item.\n",
      "reordered and are out of stock\n",
      "wish I could still get them,\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "(Score: 5)  Gift idea for those that love reading and still likes to have the actual book.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (pet_supplies) --------------------------------\n",
      "\n",
      "(Score: 5)  This toy was so much fun! My dog leaned quickly how to make it say \"Oh Noo\" and just loved pressing it. The sound did go out after a few weeks, but I think that's because my dog likes to chew, but he still plays with it and it's still all together.\n",
      "\n",
      "Great toy! Would definitely recommend for a pet lovers gift\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "(Score: 3)  Didn't last long\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (sports_and_outdoors) --------------------------------\n",
      "\n",
      "(Score: 4)  Ordered this set a couple weeks back and my wife and I both love this set to supplement our weight training.  Would give 5 stars if BMP made a fore foot cover with attached D ring for dorsiflexion (calf raises), but or now the ankle strap will suffice.  Very well made and the carabiners are very handy for quick changes.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "(Score: 5)  fun in pool and water\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (tools_and_home_improvement) --------------------------------\n",
      "\n",
      "(Score: 5)  Big upgrade over the basic edge guide. It allows for more precise accuracy and better stability.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "(Score: 5)  so it holds the bit.  My last collet got scratched or bent or something.  It wouldn't grip correctly and the bit would work its way up and down while cutting.  Aside from a bad cut it was dangerous.  This one does what the other used to do.  It holds the bit like it is supposed to.  Plus I like the retaining ring to hold the nut to the collet.  Makes it easier to change the collet size all at once, no finding parts and such.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (video_games) --------------------------------\n",
      "\n",
      "(Score: 5)  Fantastic condition!\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "(Score: 5)  This worked great for my needs, my kids are able to have all their games hooked up.  Easy to connect and set up.\n",
      "\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# NOTE:  It appears that 'books' contains some reviews that regard remotes / chargers ...\n",
    "\n",
    "def show_reviews(nsample=1):\n",
    "    for group in reviews_data.groupby('type'):\n",
    "        group = group[1].reset_index()\n",
    "        print('---------------------------------- ({t}) --------------------------------'.format(t=group['type'][0]))\n",
    "        for _, row in group.sample(n=nsample).iterrows():\n",
    "            print('\\n(Score: {s})  {r}\\n'.format(s=row['overall'], r=row['reviewText']))\n",
    "            print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "show_reviews(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c258f342",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8bf8e08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- (all) --------------\n",
      "# Reviews:   41290\n",
      "# Unique words:   111034\n",
      "# Unique characters:   98\n",
      "Average Review Length:   381.81 chars\n",
      "Average Overall Rating:   4.37\n",
      "\n",
      "------------- (appliances) --------------\n",
      "# Reviews:   2277\n",
      "# Unique words:   1986\n",
      "# Unique characters:   87\n",
      "Average Review Length:   1481.95 chars\n",
      "Average Overall Rating:   4.5\n",
      "\n",
      "------------- (arts_crafts_and_sewing) --------------\n",
      "# Reviews:   3001\n",
      "# Unique words:   13254\n",
      "# Unique characters:   91\n",
      "Average Review Length:   207.92 chars\n",
      "Average Overall Rating:   4.57\n",
      "\n",
      "------------- (automotive) --------------\n",
      "# Reviews:   3001\n",
      "# Unique words:   15773\n",
      "# Unique characters:   93\n",
      "Average Review Length:   244.68 chars\n",
      "Average Overall Rating:   4.34\n",
      "\n",
      "------------- (books) --------------\n",
      "# Reviews:   3001\n",
      "# Unique words:   23091\n",
      "# Unique characters:   92\n",
      "Average Review Length:   429.42 chars\n",
      "Average Overall Rating:   4.21\n",
      "\n",
      "------------- (cellphones_and_accessories) --------------\n",
      "# Reviews:   3001\n",
      "# Unique words:   24945\n",
      "# Unique characters:   93\n",
      "Average Review Length:   529.87 chars\n",
      "Average Overall Rating:   3.89\n",
      "\n",
      "------------- (clothing_shoes_and_jewelry) --------------\n",
      "# Reviews:   3001\n",
      "# Unique words:   11051\n",
      "# Unique characters:   91\n",
      "Average Review Length:   168.8 chars\n",
      "Average Overall Rating:   4.17\n",
      "\n",
      "------------- (fashion) --------------\n",
      "# Reviews:   3001\n",
      "# Unique words:   2282\n",
      "# Unique characters:   80\n",
      "Average Review Length:   130.35 chars\n",
      "Average Overall Rating:   4.4\n",
      "\n",
      "------------- (home_and_kitchen) --------------\n",
      "# Reviews:   3001\n",
      "# Unique words:   16588\n",
      "# Unique characters:   94\n",
      "Average Review Length:   252.47 chars\n",
      "Average Overall Rating:   4.41\n",
      "\n",
      "------------- (movies_and_tv) --------------\n",
      "# Reviews:   3001\n",
      "# Unique words:   28987\n",
      "# Unique characters:   92\n",
      "Average Review Length:   445.91 chars\n",
      "Average Overall Rating:   4.41\n",
      "\n",
      "------------- (office_products) --------------\n",
      "# Reviews:   3001\n",
      "# Unique words:   15169\n",
      "# Unique characters:   91\n",
      "Average Review Length:   233.52 chars\n",
      "Average Overall Rating:   4.59\n",
      "\n",
      "------------- (pet_supplies) --------------\n",
      "# Reviews:   3001\n",
      "# Unique words:   15412\n",
      "# Unique characters:   95\n",
      "Average Review Length:   288.55 chars\n",
      "Average Overall Rating:   4.29\n",
      "\n",
      "------------- (sports_and_outdoors) --------------\n",
      "# Reviews:   3001\n",
      "# Unique words:   15035\n",
      "# Unique characters:   91\n",
      "Average Review Length:   258.44 chars\n",
      "Average Overall Rating:   4.51\n",
      "\n",
      "------------- (tools_and_home_improvement) --------------\n",
      "# Reviews:   3001\n",
      "# Unique words:   15880\n",
      "# Unique characters:   94\n",
      "Average Review Length:   301.82 chars\n",
      "Average Overall Rating:   4.5\n",
      "\n",
      "------------- (video_games) --------------\n",
      "# Reviews:   3001\n",
      "# Unique words:   32284\n",
      "# Unique characters:   97\n",
      "Average Review Length:   637.01 chars\n",
      "Average Overall Rating:   4.42\n",
      "\n",
      "\n",
      "------------------- Score Summaries -------------------\n",
      "                            \tavg rating\tmax\tmin\n",
      "\n",
      "appliances                  \t4.49978041\t1\t5\n",
      "arts_crafts_and_sewing      \t4.56981006\t1\t5\n",
      "automotive                  \t4.33755415\t1\t5\n",
      "books                       \t4.20759747\t1\t5\n",
      "cellphones_and_accessories  \t3.89203599\t1\t5\n",
      "clothing_shoes_and_jewelry  \t4.17227591\t1\t5\n",
      "fashion                     \t4.39886704\t1\t5\n",
      "home_and_kitchen            \t4.41452849\t1\t5\n",
      "movies_and_tv               \t4.40753082\t1\t5\n",
      "office_products             \t4.59380207\t1\t5\n",
      "pet_supplies                \t4.29223592\t1\t5\n",
      "sports_and_outdoors         \t4.50516495\t1\t5\n",
      "tools_and_home_improvement  \t4.50016661\t1\t5\n",
      "video_games                 \t4.42485838\t1\t5\n",
      "\n",
      "Possible values for 'overall':\t [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "LEFT_ADJUST = 28\n",
    "\n",
    "for dataset in ['all', *reviews_data['type'].unique()]:\n",
    "    data = reviews_data if (dataset=='all') else reviews_data[reviews_data['type']==dataset]\n",
    "    \n",
    "    word_tokens = set()  # lowercase only\n",
    "    char_tokens = set()  # lowercase only\n",
    "    sum_rev_len = 0\n",
    "    for text in data['reviewText']:\n",
    "        if type(text) == str:\n",
    "            sum_rev_len += len(text)\n",
    "            for token in re.split(r'\\s{1,}', text):  word_tokens.add(token)\n",
    "            for c in text:  char_tokens.add(c)\n",
    "    print(\"------------- ({s}) --------------\".format(s=dataset))\n",
    "    print(\"# Reviews:  \", len(data))\n",
    "    print(\"# Unique words:  \", len(word_tokens))\n",
    "    print(\"# Unique characters:  \", len(char_tokens))\n",
    "    print(\"Average Review Length:  \", np.round_(sum_rev_len / len(data), 2), \"chars\")\n",
    "    print(\"Average Overall Rating:  \", np.round_(data['overall'].mean(), 2))\n",
    "    print()\n",
    "print()\n",
    "print(\"------------------- Score Summaries -------------------\")\n",
    "print((\" \"*LEFT_ADJUST + \"\\tavg rating\\tmax\\tmin\\n\"))\n",
    "for group in reviews_data.groupby('type'):\n",
    "    df = group[1]\n",
    "    print(group[0].ljust(LEFT_ADJUST) + \"\\t{avg}\\t{mx}\\t{mn}\".format(\n",
    "        avg=np.round_(df['overall'].mean(), 8),\n",
    "        mn=df['overall'].max(),\n",
    "        mx=df['overall'].min()\n",
    "    ))\n",
    "print()\n",
    "print(\"Possible values for 'overall':\\t\", sorted(reviews_data['overall'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f45d0",
   "metadata": {},
   "source": [
    "# Essays\n",
    "\n",
    "This dataset contains 8 different essay sets, each associated with a particular prompt.\n",
    "* Personally identifying information has been replaced with NER (Named Entity Recognition) tags [Ex: \"Person\", \"Organization\", etc.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdca4b1",
   "metadata": {},
   "source": [
    "## Loading (and cleaning) Data\n",
    "\n",
    "* All of the score columns were of datatype ('object'), and missing values were ('').\n",
    "\n",
    " **Steps for Cleaning Data:**\n",
    " \n",
    "   1) Replace '' with nans (NULLs)\n",
    " \n",
    "   2) Convert score columns to int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "38cef46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_train, essays_valid, essays_test = load_essays()  # (train, valid, test)\n",
    "\n",
    "for df in [essays_train, essays_valid, essays_test]:\n",
    "    df.replace('', np.nan, inplace=True)\n",
    "    for col in (c for c in df.columns if c not in ['essay_id', 'essay_set', 'essay']):\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc6f254",
   "metadata": {},
   "source": [
    "### Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7152958c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4            <NA>              8   \n",
       "1               5               4            <NA>              9   \n",
       "2               4               3            <NA>              7   \n",
       "3               5               5            <NA>             10   \n",
       "4               4               4            <NA>              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "0            <NA>            <NA>           <NA>  ...           <NA>   \n",
       "1            <NA>            <NA>           <NA>  ...           <NA>   \n",
       "2            <NA>            <NA>           <NA>  ...           <NA>   \n",
       "3            <NA>            <NA>           <NA>  ...           <NA>   \n",
       "4            <NA>            <NA>           <NA>  ...           <NA>   \n",
       "\n",
       "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "0           <NA>           <NA>           <NA>           <NA>           <NA>   \n",
       "1           <NA>           <NA>           <NA>           <NA>           <NA>   \n",
       "2           <NA>           <NA>           <NA>           <NA>           <NA>   \n",
       "3           <NA>           <NA>           <NA>           <NA>           <NA>   \n",
       "4           <NA>           <NA>           <NA>           <NA>           <NA>   \n",
       "\n",
       "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0           <NA>           <NA>           <NA>           <NA>  \n",
       "1           <NA>           <NA>           <NA>           <NA>  \n",
       "2           <NA>           <NA>           <NA>           <NA>  \n",
       "3           <NA>           <NA>           <NA>           <NA>  \n",
       "4           <NA>           <NA>           <NA>           <NA>  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb5aebb",
   "metadata": {},
   "source": [
    "### Valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc40ab99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_predictionid</th>\n",
       "      <th>domain2_predictionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, @CAPS1 more and more peop...</td>\n",
       "      <td>1788</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1 Time @CAPS1 me tell you what I...</td>\n",
       "      <td>1789</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local newspaper, Have you been spending a...</td>\n",
       "      <td>1790</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Readers, @CAPS1 you imagine how life woul...</td>\n",
       "      <td>1791</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear newspaper, I strongly believe that comput...</td>\n",
       "      <td>1792</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      1788          1  Dear @ORGANIZATION1, @CAPS1 more and more peop...   \n",
       "1      1789          1  Dear @LOCATION1 Time @CAPS1 me tell you what I...   \n",
       "2      1790          1  Dear Local newspaper, Have you been spending a...   \n",
       "3      1791          1  Dear Readers, @CAPS1 you imagine how life woul...   \n",
       "4      1792          1  Dear newspaper, I strongly believe that comput...   \n",
       "\n",
       "   domain1_predictionid domain2_predictionid  \n",
       "0                  1788                       \n",
       "1                  1789                       \n",
       "2                  1790                       \n",
       "3                  1791                       \n",
       "4                  1792                       "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ec3f1e",
   "metadata": {},
   "source": [
    "### Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92be202d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_predictionid</th>\n",
       "      <th>domain2_predictionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I believe that computers have a positive effec...</td>\n",
       "      <td>2383.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dear @CAPS1, I know some problems have came up...</td>\n",
       "      <td>2384.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dear to whom it @MONTH1 concern, Computers are...</td>\n",
       "      <td>2385.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2386</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, @CAPS3 has come to my atte...</td>\n",
       "      <td>2386.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2387</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dear Local newspaper, I think that people have...</td>\n",
       "      <td>2387.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id  essay_set                                              essay  \\\n",
       "0     2383        1.0  I believe that computers have a positive effec...   \n",
       "1     2384        1.0  Dear @CAPS1, I know some problems have came up...   \n",
       "2     2385        1.0  Dear to whom it @MONTH1 concern, Computers are...   \n",
       "3     2386        1.0  Dear @CAPS1 @CAPS2, @CAPS3 has come to my atte...   \n",
       "4     2387        1.0  Dear Local newspaper, I think that people have...   \n",
       "\n",
       "   domain1_predictionid domain2_predictionid  \n",
       "0                2383.0                       \n",
       "1                2384.0                       \n",
       "2                2385.0                       \n",
       "3                2386.0                       \n",
       "4                2387.0                       "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792e06fe",
   "metadata": {},
   "source": [
    "### Ratings Overview (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9633b50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>rater1_trait1</th>\n",
       "      <th>rater1_trait2</th>\n",
       "      <th>rater1_trait3</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12977.000000</td>\n",
       "      <td>12977.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>12977.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>723.000000</td>\n",
       "      <td>723.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.126840</td>\n",
       "      <td>4.137089</td>\n",
       "      <td>37.828125</td>\n",
       "      <td>6.799723</td>\n",
       "      <td>3.333889</td>\n",
       "      <td>3.330556</td>\n",
       "      <td>3.333889</td>\n",
       "      <td>2.444154</td>\n",
       "      <td>2.557592</td>\n",
       "      <td>2.606457</td>\n",
       "      <td>...</td>\n",
       "      <td>2.635689</td>\n",
       "      <td>2.710297</td>\n",
       "      <td>3.777317</td>\n",
       "      <td>3.589212</td>\n",
       "      <td>3.945312</td>\n",
       "      <td>3.890625</td>\n",
       "      <td>4.078125</td>\n",
       "      <td>3.992188</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>3.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.212537</td>\n",
       "      <td>4.264320</td>\n",
       "      <td>5.240829</td>\n",
       "      <td>8.970558</td>\n",
       "      <td>0.729103</td>\n",
       "      <td>0.726807</td>\n",
       "      <td>0.729103</td>\n",
       "      <td>1.211730</td>\n",
       "      <td>1.061076</td>\n",
       "      <td>1.098196</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142566</td>\n",
       "      <td>1.045795</td>\n",
       "      <td>0.689401</td>\n",
       "      <td>0.693256</td>\n",
       "      <td>0.643668</td>\n",
       "      <td>0.630390</td>\n",
       "      <td>0.622535</td>\n",
       "      <td>0.509687</td>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.603417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "count    12977.000000    12977.000000      128.000000   12977.000000   \n",
       "mean         4.126840        4.137089       37.828125       6.799723   \n",
       "std          4.212537        4.264320        5.240829       8.970558   \n",
       "min          0.000000        0.000000       20.000000       0.000000   \n",
       "25%          2.000000        2.000000       36.000000       2.000000   \n",
       "50%          3.000000        3.000000       40.000000       3.000000   \n",
       "75%          4.000000        4.000000       40.000000       8.000000   \n",
       "max         30.000000       30.000000       50.000000      60.000000   \n",
       "\n",
       "       rater1_domain2  rater2_domain2  domain2_score  rater1_trait1  \\\n",
       "count     1800.000000     1800.000000    1800.000000    2292.000000   \n",
       "mean         3.333889        3.330556       3.333889       2.444154   \n",
       "std          0.729103        0.726807       0.729103       1.211730   \n",
       "min          1.000000        1.000000       1.000000       0.000000   \n",
       "25%          3.000000        3.000000       3.000000       2.000000   \n",
       "50%          3.000000        3.000000       3.000000       2.000000   \n",
       "75%          4.000000        4.000000       4.000000       3.000000   \n",
       "max          4.000000        4.000000       4.000000       6.000000   \n",
       "\n",
       "       rater1_trait2  rater1_trait3  ...  rater2_trait3  rater2_trait4  \\\n",
       "count    2292.000000    2292.000000  ...    2292.000000    2292.000000   \n",
       "mean        2.557592       2.606457  ...       2.635689       2.710297   \n",
       "std         1.061076       1.098196  ...       1.142566       1.045795   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         2.000000       2.000000  ...       2.000000       2.000000   \n",
       "50%         2.000000       2.000000  ...       2.000000       3.000000   \n",
       "75%         3.000000       4.000000  ...       4.000000       3.000000   \n",
       "max         6.000000       6.000000  ...       6.000000       6.000000   \n",
       "\n",
       "       rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "count     723.000000     723.000000     128.000000     128.000000   \n",
       "mean        3.777317       3.589212       3.945312       3.890625   \n",
       "std         0.689401       0.693256       0.643668       0.630390   \n",
       "min         1.000000       1.000000       2.000000       2.000000   \n",
       "25%         3.000000       3.000000       4.000000       4.000000   \n",
       "50%         4.000000       4.000000       4.000000       4.000000   \n",
       "75%         4.000000       4.000000       4.000000       4.000000   \n",
       "max         6.000000       6.000000       6.000000       6.000000   \n",
       "\n",
       "       rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "count     128.000000     128.000000     128.000000     128.000000  \n",
       "mean        4.078125       3.992188       3.843750       3.617188  \n",
       "std         0.622535       0.509687       0.538845       0.603417  \n",
       "min         2.000000       3.000000       2.000000       2.000000  \n",
       "25%         4.000000       4.000000       4.000000       3.000000  \n",
       "50%         4.000000       4.000000       4.000000       4.000000  \n",
       "75%         4.000000       4.000000       4.000000       4.000000  \n",
       "max         6.000000       6.000000       5.000000       5.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_columns = [c for c in essays_train.columns if c not in ['essay_id', 'essay_set', 'essay']]\n",
    "essays_train[score_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02a6500",
   "metadata": {},
   "source": [
    "### Ratings Overview (by Group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d4843c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tSet 1\t Set 2\t Set 3\t Set 4\t Set 5\t Set 6\t Set 7\t Set 8\n",
      "\t\t\t---------------------------------------------------------------\n",
      "\n",
      "rater1_domain1 (count):\t1783 \t1800 \t1726 \t1771 \t1805 \t1800 \t1569 \t723\n",
      "rater1_domain1 (mean):\t4.26 \t3.42 \t1.74 \t1.32 \t2.22 \t2.56 \t8.02 \t18.34\n",
      "rater1_domain1 (min):\t1 \t1 \t0 \t0 \t0 \t0 \t0 \t5\n",
      "rater1_domain1 (max):\t6 \t6 \t3 \t3 \t4 \t4 \t12 \t30\n",
      "\n",
      "rater2_domain1 (count):\t1783 \t1800 \t1726 \t1771 \t1805 \t1800 \t1569 \t723\n",
      "rater2_domain1 (mean):\t4.27 \t3.44 \t1.7 \t1.32 \t2.22 \t2.55 \t8.04 \t18.56\n",
      "rater2_domain1 (min):\t1 \t1 \t0 \t0 \t0 \t0 \t0 \t5\n",
      "rater2_domain1 (max):\t6 \t6 \t3 \t3 \t4 \t4 \t12 \t30\n",
      "\n",
      "rater3_domain1 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t0 \t128\n",
      "rater3_domain1 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t37.83\n",
      "rater3_domain1 (min):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t20\n",
      "rater3_domain1 (max):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t50\n",
      "\n",
      "domain1_score (count):\t1783 \t1800 \t1726 \t1771 \t1805 \t1800 \t1569 \t723\n",
      "domain1_score (mean):\t8.53 \t3.42 \t1.85 \t1.43 \t2.41 \t2.72 \t16.06 \t36.95\n",
      "domain1_score (min):\t2 \t1 \t0 \t0 \t0 \t0 \t2 \t10\n",
      "domain1_score (max):\t12 \t6 \t3 \t3 \t4 \t4 \t24 \t60\n",
      "\n",
      "rater1_domain2 (count):\t0 \t1800 \t0 \t0 \t0 \t0 \t0 \t0\n",
      "rater1_domain2 (mean):\tNone \t3.33 \tNone \tNone \tNone \tNone \tNone \tNone\n",
      "rater1_domain2 (min):\tNone \t1 \tNone \tNone \tNone \tNone \tNone \tNone\n",
      "rater1_domain2 (max):\tNone \t4 \tNone \tNone \tNone \tNone \tNone \tNone\n",
      "\n",
      "rater2_domain2 (count):\t0 \t1800 \t0 \t0 \t0 \t0 \t0 \t0\n",
      "rater2_domain2 (mean):\tNone \t3.33 \tNone \tNone \tNone \tNone \tNone \tNone\n",
      "rater2_domain2 (min):\tNone \t1 \tNone \tNone \tNone \tNone \tNone \tNone\n",
      "rater2_domain2 (max):\tNone \t4 \tNone \tNone \tNone \tNone \tNone \tNone\n",
      "\n",
      "domain2_score (count):\t0 \t1800 \t0 \t0 \t0 \t0 \t0 \t0\n",
      "domain2_score (mean):\tNone \t3.33 \tNone \tNone \tNone \tNone \tNone \tNone\n",
      "domain2_score (min):\tNone \t1 \tNone \tNone \tNone \tNone \tNone \tNone\n",
      "domain2_score (max):\tNone \t4 \tNone \tNone \tNone \tNone \tNone \tNone\n",
      "\n",
      "rater1_trait1 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t1569 \t723\n",
      "rater1_trait1 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \t1.84 \t3.76\n",
      "rater1_trait1 (min):\tNone \tNone \tNone \tNone \tNone \tNone \t0 \t1\n",
      "rater1_trait1 (max):\tNone \tNone \tNone \tNone \tNone \tNone \t3 \t6\n",
      "\n",
      "rater1_trait2 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t1569 \t723\n",
      "rater1_trait2 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \t2.02 \t3.72\n",
      "rater1_trait2 (min):\tNone \tNone \tNone \tNone \tNone \tNone \t0 \t1\n",
      "rater1_trait2 (max):\tNone \tNone \tNone \tNone \tNone \tNone \t3 \t6\n",
      "\n",
      "rater1_trait3 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t1569 \t723\n",
      "rater1_trait3 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \t1.99 \t3.94\n",
      "rater1_trait3 (min):\tNone \tNone \tNone \tNone \tNone \tNone \t0 \t1\n",
      "rater1_trait3 (max):\tNone \tNone \tNone \tNone \tNone \tNone \t3 \t6\n",
      "\n",
      "rater1_trait4 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t1569 \t723\n",
      "rater1_trait4 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \t2.17 \t3.86\n",
      "rater1_trait4 (min):\tNone \tNone \tNone \tNone \tNone \tNone \t0 \t1\n",
      "rater1_trait4 (max):\tNone \tNone \tNone \tNone \tNone \tNone \t3 \t6\n",
      "\n",
      "rater1_trait5 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t0 \t723\n",
      "rater1_trait5 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t3.73\n",
      "rater1_trait5 (min):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t1\n",
      "rater1_trait5 (max):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t6\n",
      "\n",
      "rater1_trait6 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t0 \t723\n",
      "rater1_trait6 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t3.56\n",
      "rater1_trait6 (min):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t1\n",
      "rater1_trait6 (max):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t6\n",
      "\n",
      "rater2_trait1 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t1569 \t723\n",
      "rater2_trait1 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \t1.85 \t3.83\n",
      "rater2_trait1 (min):\tNone \tNone \tNone \tNone \tNone \tNone \t0 \t1\n",
      "rater2_trait1 (max):\tNone \tNone \tNone \tNone \tNone \tNone \t3 \t6\n",
      "\n",
      "rater2_trait2 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t1569 \t723\n",
      "rater2_trait2 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \t2.03 \t3.77\n",
      "rater2_trait2 (min):\tNone \tNone \tNone \tNone \tNone \tNone \t0 \t1\n",
      "rater2_trait2 (max):\tNone \tNone \tNone \tNone \tNone \tNone \t3 \t6\n",
      "\n",
      "rater2_trait3 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t1569 \t723\n",
      "rater2_trait3 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \t2.0 \t4.02\n",
      "rater2_trait3 (min):\tNone \tNone \tNone \tNone \tNone \tNone \t0 \t1\n",
      "rater2_trait3 (max):\tNone \tNone \tNone \tNone \tNone \tNone \t3 \t6\n",
      "\n",
      "rater2_trait4 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t1569 \t723\n",
      "rater2_trait4 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \t2.17 \t3.89\n",
      "rater2_trait4 (min):\tNone \tNone \tNone \tNone \tNone \tNone \t0 \t1\n",
      "rater2_trait4 (max):\tNone \tNone \tNone \tNone \tNone \tNone \t3 \t6\n",
      "\n",
      "rater2_trait5 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t0 \t723\n",
      "rater2_trait5 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t3.78\n",
      "rater2_trait5 (min):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t1\n",
      "rater2_trait5 (max):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t6\n",
      "\n",
      "rater2_trait6 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t0 \t723\n",
      "rater2_trait6 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t3.59\n",
      "rater2_trait6 (min):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t1\n",
      "rater2_trait6 (max):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t6\n",
      "\n",
      "rater3_trait1 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t0 \t128\n",
      "rater3_trait1 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t3.95\n",
      "rater3_trait1 (min):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t2\n",
      "rater3_trait1 (max):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t6\n",
      "\n",
      "rater3_trait2 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t0 \t128\n",
      "rater3_trait2 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t3.89\n",
      "rater3_trait2 (min):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t2\n",
      "rater3_trait2 (max):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t6\n",
      "\n",
      "rater3_trait3 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t0 \t128\n",
      "rater3_trait3 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t4.08\n",
      "rater3_trait3 (min):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t2\n",
      "rater3_trait3 (max):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t6\n",
      "\n",
      "rater3_trait4 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t0 \t128\n",
      "rater3_trait4 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t3.99\n",
      "rater3_trait4 (min):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t3\n",
      "rater3_trait4 (max):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t6\n",
      "\n",
      "rater3_trait5 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t0 \t128\n",
      "rater3_trait5 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t3.84\n",
      "rater3_trait5 (min):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t2\n",
      "rater3_trait5 (max):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t5\n",
      "\n",
      "rater3_trait6 (count):\t0 \t0 \t0 \t0 \t0 \t0 \t0 \t128\n",
      "rater3_trait6 (mean):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t3.62\n",
      "rater3_trait6 (min):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t2\n",
      "rater3_trait6 (max):\tNone \tNone \tNone \tNone \tNone \tNone \tNone \t5\n"
     ]
    }
   ],
   "source": [
    "score_columns = [c for c in essays_train.columns if c not in ['essay_id', 'essay']]\n",
    "metrics = ['count', 'mean', 'min', 'max']\n",
    "op_dict = {\n",
    "    'count': lambda x: x.astype(int),\n",
    "    'min': lambda x: x.astype(int),\n",
    "    'max': lambda x: x.astype(int),\n",
    "    'mean': lambda x: np.round_(x, 2)\n",
    "}\n",
    "def reformat(x, metric):\n",
    "    x = np.array(x)\n",
    "    return \"None\" if pd.isnull(x) else op_dict[metric](x)\n",
    "\n",
    "print(\"\\t\\t\\tSet 1\\t Set 2\\t Set 3\\t Set 4\\t Set 5\\t Set 6\\t Set 7\\t Set 8\")\n",
    "print(\"\\t\\t\\t---------------------------------------------------------------\")\n",
    "current_column = None\n",
    "df = essays_train[score_columns].groupby('essay_set').describe()\n",
    "for entry in df:\n",
    "    if current_column != entry[0]:\n",
    "        print()\n",
    "        current_column = entry[0]\n",
    "    if entry[1] in metrics:\n",
    "        score_params = {'s'+str(set_id): reformat(df[entry][set_id], entry[1]) for set_id in range(1, 9)}\n",
    "        print((\"{t} ({m}):\\t{s1} \\t{s2} \\t{s3} \\t{s4} \\t{s5} \\t{s6} \\t{s7} \\t{s8}\").format(\n",
    "            t=entry[0], m=entry[1], **score_params))\n",
    "        \n",
    "# NOTE:  'count' is how many non-NULL rows\n",
    "        \n",
    "# -------------------- OBSERVATIONS --------------------\n",
    "#\n",
    "# -  All Sets Have:   'rater1_domain1', 'rater2_domain1', and 'domain1_score'\n",
    "# -  Set 8 has all scores except in domain 2\n",
    "#\n",
    "#    Given that only these three columns ('rater1_domain1', 'rater2_domain1', 'domain1_score') have values in every\n",
    "#    set category, it's best to choose the column relating to the overall score among these three ('domain1_score')\n",
    "#    as the score we'll use for our label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc9b28",
   "metadata": {},
   "source": [
    "### Sample Essays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "821dce76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------- (Set 1) --------------------------------\n",
      "\n",
      "(Score: 11)  Dear @LOCATION1, @CAPS1 you imagine where the world would be without computers? Our daily lives would be dull and boring without new technology. Computers help society do various activities that would be impossible if we didn't have computers. They give us the ability to learn at home, connect with other people, and give a source of entertainment. From these reasons our lives because easy and convenient, which is what @CAPS2 people strive to accomplish. The ability for an average person to learn has greatly increased. It has gone from just being able to go to school to the @CAPS2 various ways to increase your intelligence on the computer. Programs such as @ORGANIZATION1, which teaches people how to speak a language, are available on the computer. These programs are like going to school, but more accesible to the public. To further help the public, there are ways to gain college degrees online. that how . Even if you go to school a computer @CAPS1 still help you excel in you work @CAPS2 sources of research are available on the computer and you like to the web a computer is a great place for fun. However, people still think computers are good. They claim to gaining on the other hand, the computer gives people website to help lose weight.They also say people aren't enjoying nature, even though there are @CAPS2 ways to appreciate on the computer. Lastly, it is stated that you dont . To conclude, computers greatly benefit us and are good. New technology is good thing and should keep expanding because of gaining the ability to , conncet with people and having fun, a computer helps the general public. Please, think of what i have said and buy a computer!\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (Set 2) --------------------------------\n",
      "\n",
      "(Score: 3)  Censorship in Libraries     Censorship in libraries is a big problem in today's society, many people get angry at libraries and markets because of the items that they have on display for the common consumer. If the consumer walks into a library and is looking for a book to read. What if they come accross a book from the early @DATE1's? In these times there were lots of words used that are 'harmful' to our people today, but what most people dont understand is that, these words that are harmful had different meanings in that time in history. So when someone picks up a book and finds harmful or un-appropriate words or phrases in them, they instantly get the wrong idea about the book. And then, this small group of people who dont like this piece of literature, go agains the vast majority of people who really do understand the literature, and the feeling and dialect of the book. That is where i am going to explain to this small group of people, a few details that they should keep in mind when trying to rip a book off of the shelf and throwing it away.     When someone goes into a store or library and starts to look for a book, they @MONTH1 come accross a piece of literature that they dont completely agree with. When this person comes across this piece of literature, all they have to do is put it back on the shelf and move on. Nobody is forcing that person to read this book, so why make a big deal about it?  Because most people who make a big deal about some of the word usage in a book, dont quite understand the dialect of the book, or the time period the book was written in. If you do not understand the literature completely, then i ask that these people do not make a big scene out of it, and that they dont try to revoke the author's rights to have that piece of literature on the shelf.          Authors have just as many rights as we do. If they write literature. A poem, novel, or even a short story, these authors have the right to have it published and put on the shelf. So why would we not have the same rights? If we dont agree with some of the literature that are being placed in our society's schools, stores, and homes. Then we can write a novel, newspaper article, or even make a website about your topic. You can make web polls much more. This is a more indirect approach to removing a piece of literature. If you want to have a better chance of this book or novel to be removed from the shelves, you can use a poll or have people vote, to recieve other people's oppinions, and use these in your argument. If you have more than one oppinion on a subject, you @MONTH1 have a more likely chance of winning your argument. And this will cause a lot less chaos and attention to be drawn to yourself and others around you.     Another reason why i dont think that people should be able to choose what is on the shelves of libraries everywhere. I do not think that anybody from anywhere shoudl be able to come into a library and take a piece of literature off of the shelves forever. Because, in todays society, we have researchers going all of the time, and we have so many people working on different theories and laws. So if we take one important book off of the shelf, maybe a book written in the @DATE2's about evolution. And we get rid of all of these books, what will happen when we really need that information? These scientists @MONTH1 need that piece of literature to test a theory, and if that piece of literature is expelled from the shelves, then we could miss out on a large variety of major information that could help out someone in the future. So the more information we take off of the shelves, the less we will have in the future to help us will our problems.     So, now that i have told you all of my opinions on this subject, i hope that you will have a better view on the cencorship of libraries everywhere. And that maybe someday all books and pieces of literature will be able to remain on the shelves, being endlessly read by consumers\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (Set 3) --------------------------------\n",
      "\n",
      "(Score: 3)  The cyclist in �Do Not Exceed Posted Speed @CAPS1� was riding through the California dessert in June. This dry, bare setting made it impossible to find any source of water. The only time that this cyclist found water was when it @NUM1 and tasting of battery acid. There was nowhere for him to find water for miles. This lack of water and scorching heat made him travel slow and wearily. He even says that he could only go 12 mph in a 55 mph zone. By taking the advise of the old men and taking a �short cut�, the cyclist past through ghost towns with no water. This �short cut� prolonged his trip, most likely by hours If he had gone through populated area despite the fact that it is a longer path, there would have been more water to drink, which would allow him to go faster. The dry, hot setting of the old men�s �short cut� made this cyclist�s trip last much longer than nessiarry.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (Set 4) --------------------------------\n",
      "\n",
      "(Score: 3)  In the �passage winter Hibiscus� by monfong Ho, the quote � when they come back, Saeng vowed silently, in the spring, when the snows melt and the geese return and the hibiscus is budding, I will take the test again, it symbolizes @CAPS1 new journey in the new country she lives in. In the test Saeng is having a personal discrepancy, missing her homeland @CAPS2 she states �I � failed the test.� This test meant more to then she just failing. She was a test to her ability to function in her new country and she failed. The � when they came back�� quote started above can be analyzed deeply as the snow being her obstacles and the hibiscus being herself. When the obstacles melt away and she buds into a new stronger person she will take the test again.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (Set 5) --------------------------------\n",
      "\n",
      "(Score: 2)  So the mood of this memoir is @CAPS1, Struggle or not so good and @CAPS2. In the @CAPS3 it telling you all about His parent and alot more about His parent's. Next is talk about Being born in a simple house and that way @CAPS1 mood there to. So @CAPS4 the end of the memoire @CAPS5 startes to talk about the @CAPS6 things like not Be able to find the kind or jod they deserved and that not that much @CAPS6 thing @CAPS5 talk But But in the end @CAPS5 @CAPS10 the definition of @CAPS11 and that mood is alsome. Then @CAPS5 learne there about love in the simple house and to never forgot how my Parents turned the simple house to a home. So the mood is a mix of @CAPS1, @CAPS6 time's and the alsomeness and more.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (Set 6) --------------------------------\n",
      "\n",
      "(Score: 3)  The invention of the mass on top of the Empire State Building was an undeveloped idea that created created a new means of transportation but arrive with numerous flaws. One obstacle the engineers faced was resting a one thousand foot dirigible over a twelve hundred fifty foot building because with combined wind pressure this would put stress on the building's structure and allow it to collapse. This transportation was also extremely dangerous to the public because many foreign dirigibles \"used hydrogen rather than helium, and hydrogen is highly flammable (paragraph @NUM1).\" Not only this, if builders ever allowed dirigible's to dock on the building, the back of the airship would spin around the mooring mast due to shifting violent air currents as stated in paragraph @NUM2. In paragraph @NUM3, it says that an existing law would prohibit airships flying too low over urban areas. This law made docking dirigibles atop of the Empire State Building illegal because dirigibles would be above the people which was against the laws. All of these obstacles made the transportations a failure and as a result the use of the mast had disappeared.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (Set 7) --------------------------------\n",
      "\n",
      "(Score: 17)  Being patient is a wonderful thing to be. Here is example of me being patient for my birthday. My birthday was coming and I was extremly happy. I would always backtrack of my days so I had a personal calendar for counting down to it. After that I made lots of birthday lists. I went to stores to see what they had. For an example, I saw this beautiful short that had a matching belt.  @NUM1 days before my birthday I would not eat. I also went to @LOCATION1 and check out all the wonderful cakes. The day came and we went shopping for all the stuff I wanted. I conclude  ??? I was patient.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------- (Set 8) --------------------------------\n",
      "\n",
      "(Score: 24)  One day me and my friend taylor got the idea on a snow day to get his quad and tie a rope to the back he was drifting around a post he didnt see the hill and i was on the back on a slead and i flew over the quad and got about @NUM1 feet high then crashed it hurt but it was so funny we both couldnt stop laughing for ten min.then we went back to his creek it was frozen about @NUM2 inch thick then i was drven the quad and he was in the back i was driving along the bank and he was on the ice then it started to crack so i went faster so he didnt fall in then after about two min the ice cracked and he went under then i got him out and i drove as fast as the quad could go and got back to his house he changed and then he just sat there and laughted for hours about what we both did.\n",
      "\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def show_essays(nsample=1, exclude=None):\n",
    "    if not exclude: exclude = []\n",
    "    for group in essays_train.groupby('essay_set'):\n",
    "        group = group[1].reset_index()\n",
    "        if not group['essay_set'][0] in exclude:\n",
    "            print('---------------------------------- (Set {t}) --------------------------------'.format(t=group['essay_set'][0]))\n",
    "            for _, row in group.sample(n=nsample).iterrows():\n",
    "                score = row['domain1_score']\n",
    "                print('\\n(Score: {s})  {r}\\n'.format(s=score, r=row['essay']))\n",
    "                print(\"---------------------------------------------------------------------------\")\n",
    "                \n",
    "show_essays()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1e3149",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a91c578a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- (Set all) --------------\n",
      "# Essays:   12978\n",
      "# Unique words:   78395\n",
      "# Unique characters:   101\n",
      "Average Essay Length:   1215.63 chars\n",
      "\n",
      "------------- (Set 1) --------------\n",
      "# Essays:   1783\n",
      "# Unique words:   27282\n",
      "# Unique characters:   91\n",
      "Average Essay Length:   2029.33 chars\n",
      "\n",
      "------------- (Set 2) --------------\n",
      "# Essays:   1800\n",
      "# Unique words:   24810\n",
      "# Unique characters:   86\n",
      "Average Essay Length:   2097.03 chars\n",
      "\n",
      "------------- (Set 3) --------------\n",
      "# Essays:   1726\n",
      "# Unique words:   11074\n",
      "# Unique characters:   80\n",
      "Average Essay Length:   586.9 chars\n",
      "\n",
      "------------- (Set 4) --------------\n",
      "# Essays:   1772\n",
      "# Unique words:   8339\n",
      "# Unique characters:   84\n",
      "Average Essay Length:   509.48 chars\n",
      "\n",
      "------------- (Set 5) --------------\n",
      "# Essays:   1805\n",
      "# Unique words:   9118\n",
      "# Unique characters:   82\n",
      "Average Essay Length:   685.35 chars\n",
      "\n",
      "------------- (Set 6) --------------\n",
      "# Essays:   1800\n",
      "# Unique words:   9729\n",
      "# Unique characters:   85\n",
      "Average Essay Length:   892.53 chars\n",
      "\n",
      "------------- (Set 7) --------------\n",
      "# Essays:   1569\n",
      "# Unique words:   18324\n",
      "# Unique characters:   92\n",
      "Average Essay Length:   844.38 chars\n",
      "\n",
      "------------- (Set 8) --------------\n",
      "# Essays:   723\n",
      "# Unique words:   23210\n",
      "# Unique characters:   83\n",
      "Average Essay Length:   3180.26 chars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in ['all', *essays_train['essay_set'].unique()]:\n",
    "    data = essays_train if (dataset=='all') else essays_train[essays_train['essay_set']==dataset]\n",
    "    \n",
    "    word_tokens = set()  # lowercase only\n",
    "    char_tokens = set()  # lowercase only\n",
    "    sum_rev_len = 0\n",
    "    for text in data['essay']:\n",
    "        sum_rev_len += len(text)\n",
    "        for token in re.split(r'\\s{1,}', text):  word_tokens.add(token)\n",
    "        for c in text:  char_tokens.add(c)\n",
    "    print(\"------------- (Set {s}) --------------\".format(s=dataset))\n",
    "    print(\"# Essays:  \", len(data))\n",
    "    print(\"# Unique words:  \", len(word_tokens))\n",
    "    print(\"# Unique characters:  \", len(char_tokens))\n",
    "    print(\"Average Essay Length:  \", np.round_(sum_rev_len / len(data), 2), \"chars\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1322b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
